{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broke-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import talib\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stable-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetwork(models.Model):\n",
    "    \n",
    "    def __init__(self, input_sz, output_sz, hidden_sz):\n",
    "        super(DenseNetwork, self).__init__()\n",
    "        self.input_layer = layers.InputLayer(input_shape=(input_sz,))\n",
    "        self.hidden_layer = [layers.Dense(i, activation='relu') for i in hidden_sz]\n",
    "        self.output_layer = layers.Dense(output_sz, activation = 'linear')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for l in self.hidden_layer:\n",
    "            x = l(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "remarkable-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNAgent():\n",
    "\n",
    "    def __init__(self, \n",
    "                 state_size=None, \n",
    "                 action_size=None,\n",
    "                 hidden_size=[64,64],\n",
    "                 maxlen=10000,\n",
    "                 lr=0.001,\n",
    "                 batch_size=128,\n",
    "                 gamma=0.99,\n",
    "                 epsilon=1.0,\n",
    "                 epsilon_decay_factor=0.9999,\n",
    "                 epsilon_min = 0.01,\n",
    "                 Architecture=DenseNetwork):\n",
    "        \n",
    "        self.state_size = state_size  \n",
    "        self.action_size = action_size  \n",
    "        \n",
    "        self.discount_factor = gamma\n",
    "        self.learning_rate = lr\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay_factor = epsilon_decay_factor \n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.model = Architecture(self.state_size, self.action_size, self.hidden_size)\n",
    "        self.target_model = Architecture(self.state_size, self.action_size, self.hidden_size) \n",
    "        \n",
    "        self.copy_weights(self.model, self.target_model)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr=self.learning_rate)\n",
    "\n",
    "        self.maxlen = maxlen\n",
    "        self.memory = deque(maxlen=self.maxlen) \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.losses = []\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Parameter(Discount:%s, Epsilon_decay:%s, Maxlen:%s, batch:%s)\" %(self.discount_factor, \n",
    "                                                                                 self.epsilon_decay_factor, \n",
    "                                                                                 self.maxlen, \n",
    "                                                                                 self.batch_size)\n",
    "    \n",
    "    def copy_weights(self, Copy_from, Copy_to):\n",
    "        var2 = Copy_from.trainable_variables\n",
    "        var1 = Copy_to.trainable_variables\n",
    "        for v1, v2 in zip(var1, var2):\n",
    "            v1.assign(v2.numpy())\n",
    "\n",
    "    def get_action(self, state):\n",
    "        optimal_action = np.argmax(self.model.call(state)[0])\n",
    "        random_action = random.randint(0, self.action_size - 1)\n",
    "        action = np.random.choice([optimal_action, random_action], p=[1 - self.epsilon, self.epsilon])\n",
    "        return action\n",
    "    \n",
    "    def save_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay_factor\n",
    "    \n",
    "    def vanilla_loss(self, target, q):\n",
    "        return tf.keras.losses.mse(target, q)\n",
    "    \n",
    "    def train_model(self):\n",
    "        if len(self.memory) >= self.batch_size:\n",
    "            state, action, reward, next_state, done = zip(*random.sample(self.memory, self.batch_size)) \n",
    "\n",
    "            state = tf.cast(np.vstack(state), dtype=tf.float32)\n",
    "            action = tf.squeeze(tf.cast(np.vstack(action), dtype=tf.int32), axis=1) \n",
    "            reward = tf.squeeze(tf.cast(np.vstack(reward), dtype=tf.float32))\n",
    "            next_state = tf.cast(np.vstack(next_state), dtype=tf.float32)\n",
    "            done = tf.squeeze(tf.cast(np.vstack(done), dtype=tf.float32))\n",
    "            \n",
    "            q_target = self.model.call(state)\n",
    "            target_next = self.model.call(next_state) #For predict argmax next_state\n",
    "            target_val = self.target_model.call(next_state) #Predict value     \n",
    "\n",
    "            a = np.argmax(target_next, axis=1)\n",
    "            target = reward + self.discount_factor * \\\n",
    "                    np.array([target_val[i][a[i]] for i in range(self.batch_size)]) * \\\n",
    "                    (tf.ones(self.batch_size) - done)\n",
    "            \n",
    "            q_target = q_target.numpy()\n",
    "            target = target.numpy()\n",
    "            \n",
    "            q_target[np.arange(self.batch_size), list(action)] = target\n",
    "            q_target = tf.convert_to_tensor(q_target, dtype=tf.float32)\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                q_s_a = self.model.call(state)\n",
    "                \n",
    "                loss = self.vanilla_loss(q_target, q_s_a)\n",
    "                self.losses.append(loss.numpy().sum())\n",
    "                \n",
    "                gradients = tape.gradient(loss, self.model.trainable_weights)\n",
    "                \n",
    "            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_weights))\n",
    "\n",
    "            return loss    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "virgin-quantity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-0507932903ed>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(number_of_episodes)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25e64ebeff8476a87f0ced7af4f3630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "Avg_Reward: -355.8361\n",
      "Epsilon: 0.9512\n",
      "==================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0507932903ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m#take action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-4869e8f5a3c8>\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0moptimal_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mrandom_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_size\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimal_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_action\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1011\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m     return strided_slice(\n\u001b[0m\u001b[0;32m   1014\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[0;32m   1187\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10311\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10312\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10313\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m  10314\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"StridedSlice\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10315\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    env = gym.make('LunarLander-v2')\n",
    "    agent = DDQNAgent(env.observation_space.shape[0], env.action_space.n, [100,100,100], epsilon_decay_factor=0.9995, maxlen=5000)\n",
    "    number_of_episodes = 500\n",
    "    total_reward = np.zeros(number_of_episodes)\n",
    "    freq = 5\n",
    "\n",
    "    for i in tqdm_notebook(range(number_of_episodes)):\n",
    "        count = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1,env.observation_space.shape[0]])\n",
    "           \n",
    "        while True:\n",
    "            count += 1\n",
    "            env.render()\n",
    "            \n",
    "            #take action\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1,env.observation_space.shape[0]])\n",
    "            \n",
    "            agent.save_sample(state, action, reward, next_state, done)\n",
    "                \n",
    "            if count % freq == 0:\n",
    "                agent.train_model()\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward[i] += reward\n",
    "\n",
    "            if done:\n",
    "                env.render()\n",
    "                \n",
    "                if total_reward[i]>=200:\n",
    "                    agent.model.save_weights('Luna.h5')\n",
    "                \n",
    "                agent.copy_weights(agent.model, agent.target_model)\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    print(f'Episode: {i+1}')\n",
    "                    print(f\"Avg_Reward: {total_reward[:i+1].mean():.4f}\")\n",
    "                    print(f'Epsilon: {agent.epsilon:.4f}')\n",
    "                    print('='*18)\n",
    "                \n",
    "                break\n",
    "       \n",
    "    agent.model.save_weights('Luna_last.h5')\n",
    "    plt.plot(total_reward)\n",
    "    plt.plot(talib.EMA(total_reward, timeperiod=50))\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Performance',fontsize=18)\n",
    "    plt.show()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dated-breath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24a52120e80>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(agent.losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-crazy",
   "metadata": {},
   "source": [
    "# Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sharp-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gym.make('LunarLander-v2')\n",
    "model = DenseNetwork(env_test.observation_space.shape[0], env_test.action_space.n, [100,100,100])\n",
    "model.build((None, env_test.observation_space.shape[0]))\n",
    "model.load_weights('Luna_last.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confirmed-party",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1ef5f0daa667>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(number_of_episode)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecccc33aa4de4ef88fb5c5f86b227b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-1ef5f0daa667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0menv_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\envs\\box2d\\lunar_lander.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    374\u001b[0m                                      color=(0.8, 0.8, 0))\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mflip\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_always_dwm\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dwm_composition_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                     \u001b[0m_dwmapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDwmFlush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "number_of_episode = 5\n",
    "\n",
    "total_reward = np.zeros(number_of_episode)\n",
    "    \n",
    "for i in tqdm_notebook(range(number_of_episode)):\n",
    "    state = env_test.reset()\n",
    "    state = np.reshape(state, [1,env_test.observation_space.shape[0]])\n",
    "           \n",
    "    while True:\n",
    "        env_test.render()\n",
    "        \n",
    "        action = np.argmax(model.call(state)[0])\n",
    "        next_state, reward, done, _ = env_test.step(action)\n",
    "        state = np.reshape(next_state, [1,env_test.observation_space.shape[0]])\n",
    "        total_reward[i] += reward\n",
    "            \n",
    "        if done:\n",
    "            env_test.render()\n",
    "            break\n",
    "env_test.close()\n",
    "plt.plot(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-projector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-doctrine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-session",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
